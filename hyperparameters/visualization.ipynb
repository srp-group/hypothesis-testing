{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "from plotly.subplots import make_subplots\n",
    "import math\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HPO of the architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "file_path = '../protein_ARCH_HPO_results.csv'\n",
    "dataset_name = os.path.splitext(os.path.basename(file_path))[0]\n",
    "if \"dna\" in dataset_name:\n",
    "    no_features = 3\n",
    "    no_classes = 180\n",
    "    d_name = \"dna\"\n",
    "    no_params = 1314560 + 1024*no_features + 256*no_classes\n",
    "elif \"splice\" in dataset_name:\n",
    "    no_features = 2\n",
    "    no_classes = 60\n",
    "    d_name = \"splice\"\n",
    "    no_params = 1314560 + 1024*no_features + 256*no_classes\n",
    "elif \"protein\" in dataset_name:\n",
    "    no_features = 3\n",
    "    no_classes = 357\n",
    "    d_name = \"protein\"\n",
    "    no_params = 1314560 + 1024*no_features + 256*no_classes\n",
    "else:\n",
    "    no_features = 2\n",
    "    no_classes = 2\n",
    "    d_name = \"twomoons\"\n",
    "    no_params = 1314560 + 1024*no_features + 256*no_classes\n",
    "df = pd.read_csv(file_path, index_col=None, header=0)\n",
    "df['no_params'] = (df['params_no_blocks'] - 1)*(df['params_small_hidden_size']*df['params_big_hidden_size']*2 + df['params_small_hidden_size'] + df['params_big_hidden_size'])\\\n",
    "    + (df['params_small_hidden_size']*df['params_big_hidden_size'] + df['params_big_hidden_size']*no_features + df['params_small_hidden_size'] + df['params_big_hidden_size'])\\\n",
    "    + (df['params_small_hidden_size']*no_classes + no_classes)\n",
    "df = df[df['value']<2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[df.idxmin()['value']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(df['no_params'], df['value'], c='blue')\n",
    "ax.set_xlabel('Number of parameters')\n",
    "ax.set_ylabel('Validation Loss')\n",
    "ax.set_title(f'{d_name} - our model no. of parameters: {no_params}')\n",
    "best_no_params = df.iloc[df.idxmin()['value']]['no_params']\n",
    "# Adjust the layout to make room for the caption\n",
    "plt.subplots_adjust(bottom=0.2)\n",
    "caption = (f'No. of parameters of our model: {no_params:,}. Best model\\'s no. of parameters: {best_no_params:,}')\n",
    "fig.text(0.5, 0.01, caption, ha='center', fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### under-fiting thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dna = pd.read_csv('../dna_l2_results.csv', header=0, index_col=None)\n",
    "df_dna = df_dna.drop(columns=[\n",
    "    \"dataset_name\", \"reg_type\", \"reg_val\", \"data_size_pct\", \"lr\", \"seed\"\n",
    "])\n",
    "df_dna = df_dna.mean().reset_index()\n",
    "df_dna.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pro = pd.read_csv('../protein_l2_results.csv', header=0, index_col=None)\n",
    "df_pro = df_pro.drop(columns=[\n",
    "    \"dataset_name\", \"reg_type\", \"reg_val\", \"data_size_pct\", \"lr\", \"seed\"\n",
    "])\n",
    "df_pro = df_pro.mean().reset_index()\n",
    "df_pro.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spli = pd.read_csv('../splice_l2_results.csv', header=0, index_col=None)\n",
    "df_spli = df_spli.drop(columns=[\n",
    "    \"dataset_name\", \"reg_type\", \"reg_val\", \"data_size_pct\", \"lr\", \"seed\"\n",
    "])\n",
    "df_spli = df_spli.mean().reset_index()\n",
    "df_spli.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_moon = pd.read_csv('../twomoons_l2_results.csv', header=0, index_col=None)\n",
    "df_moon = df_moon.drop(columns=[\n",
    "    \"dataset_name\", \"reg_type\", \"reg_val\", \"data_size_pct\", \"lr\", \"seed\"\n",
    "])\n",
    "df_moon = df_moon.mean().reset_index()\n",
    "df_moon.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the loss and accuracy data from each dataframe\n",
    "loss_data = {\n",
    "    'Dataset': ['DNA', 'Protein', 'Splice', 'Two Moons'],\n",
    "    'Validation Loss': [df_dna.loc[df_dna['index'] == 'loss', 0].values[0],\n",
    "                        df_pro.loc[df_pro['index'] == 'loss', 0].values[0],\n",
    "                        df_spli.loc[df_spli['index'] == 'loss', 0].values[0],\n",
    "                        df_moon.loc[df_moon['index'] == 'loss', 0].values[0]],\n",
    "    'Training Loss': [df_dna.loc[df_dna['index'] == 'train_loss', 0].values[0],\n",
    "                    df_pro.loc[df_pro['index'] == 'train_loss', 0].values[0],\n",
    "                    df_spli.loc[df_spli['index'] == 'train_loss', 0].values[0],\n",
    "                    df_moon.loc[df_moon['index'] == 'train_loss', 0].values[0]]\n",
    "}\n",
    "\n",
    "acc_data = {\n",
    "    'Dataset': ['DNA', 'Protein', 'Splice', 'Two Moons'],\n",
    "    'Validation Accuracy': [df_dna.loc[df_dna['index'] == 'val_acc', 0].values[0],\n",
    "                            df_pro.loc[df_pro['index'] == 'val_acc', 0].values[0],\n",
    "                            df_spli.loc[df_spli['index'] == 'val_acc', 0].values[0],\n",
    "                            df_moon.loc[df_moon['index'] == 'val_acc', 0].values[0]],\n",
    "    'Training Accuracy': [df_dna.loc[df_dna['index'] == 'train_acc', 0].values[0],\n",
    "                        df_pro.loc[df_pro['index'] == 'train_acc', 0].values[0],\n",
    "                        df_spli.loc[df_spli['index'] == 'train_acc', 0].values[0],\n",
    "                        df_moon.loc[df_moon['index'] == 'train_acc', 0].values[0]]\n",
    "}\n",
    "\n",
    "# Convert to DataFrames\n",
    "df_loss = pd.DataFrame(loss_data)\n",
    "df_acc = pd.DataFrame(acc_data)\n",
    "\n",
    "# Plotting\n",
    "fig, ax = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Loss plot\n",
    "ax[0].plot(df_loss['Dataset'], df_loss['Validation Loss'], label='Validation Loss', color='blue', marker='o')\n",
    "ax[0].plot(df_loss['Dataset'], df_loss['Training Loss'], label='Training Loss', color='red', marker='o')\n",
    "ax[0].set_title('Loss Comparison')\n",
    "ax[0].set_xlabel('Dataset')\n",
    "ax[0].set_ylabel('Loss')\n",
    "ax[0].legend()\n",
    "\n",
    "# Accuracy plot\n",
    "ax[1].plot(df_acc['Dataset'], df_acc['Validation Accuracy'], label='Validation Accuracy', color='blue', marker='o')\n",
    "ax[1].plot(df_acc['Dataset'], df_acc['Training Accuracy'], label='Training Accuracy', color='red', marker='o')\n",
    "ax[1].set_title('Accuracy Comparison')\n",
    "ax[1].set_xlabel('Dataset')\n",
    "ax[1].set_ylabel('Accuracy')\n",
    "ax[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### results plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\"C:\\\\Users\\\\Amir Hossein\\\\Downloads\\\\cres\\\\splice_l2_results.csv\", header=0, index_col=None)\n",
    "# df = pd.read_csv(\"C:\\\\Users\\\\Amir Hossein\\\\Downloads\\\\cres\\\\splice_dropout_results.csv\", header=0, index_col=None)\n",
    "\n",
    "# df = pd.read_csv(\"C:\\\\Users\\\\Amir Hossein\\\\Downloads\\\\cres\\\\dna_l2_results.csv\", header=0, index_col=None)\n",
    "# df = pd.read_csv(\"C:\\\\Users\\\\Amir Hossein\\\\Downloads\\\\cres\\\\dna_dropout_results.csv\", header=0, index_col=None)\n",
    "\n",
    "# df = pd.read_csv(\"C:\\\\Users\\\\Amir Hossein\\\\Downloads\\\\cres\\\\twomoons_l2_results.csv\", header=0, index_col=None)\n",
    "# df = pd.read_csv(\"C:\\\\Users\\\\Amir Hossein\\\\Downloads\\\\cres\\\\twomoons_dropout_results.csv\", header=0, index_col=None)\n",
    "\n",
    "# df = pd.read_csv(\"C:\\\\Users\\\\Amir Hossein\\\\Downloads\\\\cres\\\\protein_l2_results.csv\", header=0, index_col=None)\n",
    "df = pd.read_csv(\"C:\\\\Users\\\\Amir Hossein\\\\Downloads\\\\cres\\\\protein_dropout_results.csv\", header=0, index_col=None)\n",
    "\n",
    "\n",
    "dataset = df.loc[df.groupby([\"dataset_name\", \"reg_type\", \"reg_val\", \"seed\", \"data_size_pct\"])[\"loss\"].idxmin()].reset_index(drop=True)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = dataset['dataset_name'].unique().item()\n",
    "# print(dataset_name)\n",
    "\n",
    "if dataset['reg_type'].unique().item() == 'l2':\n",
    "    reg_type = 'l2'\n",
    "    log_scale = True\n",
    "    \n",
    "else:\n",
    "    reg_type = 'dropout'\n",
    "    log_scale = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_3d_surface_with_avg(dataset, x_col, y_col, z_col, log_x=False, log_y=False, log_z=False):\n",
    "    # Group by x and y and compute the mean of the z column\n",
    "    df_grouped = dataset.groupby([x_col, y_col])[[z_col, \"lr\"]].mean().reset_index()\n",
    "\n",
    "    # Pivot the grouped data to get the correct format for the surface plot\n",
    "    df_pivot = df_grouped.pivot(index=y_col, columns=x_col, values=z_col)\n",
    "\n",
    "    # Create x, y, z values for the surface plot\n",
    "    x_vals = df_pivot.columns\n",
    "    y_vals = df_pivot.index\n",
    "    z_vals = df_pivot.values\n",
    "\n",
    "    # Create a 3D surface plot with opacity set to 0.6 and contours on the z-axis\n",
    "    surface = go.Surface(\n",
    "        z=z_vals, \n",
    "        x=x_vals, \n",
    "        y=y_vals, \n",
    "        opacity=0.9, \n",
    "        colorscale='Jet',\n",
    "        contours={\n",
    "            \"z\": {\n",
    "                \"show\": True,  # Enable contour lines on the z-axis\n",
    "                # \"project\": {\"z\": True},  # Project contour lines onto the z-plane\n",
    "                \"color\": \"black\",  # Color of the contour lines\n",
    "                \"width\": 2  # Thickness of the contour lines\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Add a 3D scatter plot with the same data points\n",
    "    scatter_data = go.Scatter3d(\n",
    "        x=df_grouped[x_col], \n",
    "        y=df_grouped[y_col], \n",
    "        z=df_grouped[z_col],\n",
    "        mode='markers',\n",
    "        marker=dict(size=5, color=df_grouped[z_col], colorscale='Jet', opacity=0.9),\n",
    "        hovertext=[\n",
    "            f\"{x_col}: {x}<br>{y_col}: {y}<br>{z_col}: {z}<br>Learning Rate: {lr}\"\n",
    "            for x, y, z, lr in zip(df_grouped[x_col], df_grouped[y_col], df_grouped[z_col], df_grouped[\"lr\"])\n",
    "        ],\n",
    "        hoverinfo=\"text\"\n",
    "    )\n",
    "\n",
    "    # Identify the row with the minimum z_col value\n",
    "    min_row = df_grouped.loc[df_grouped[z_col].idxmin()]\n",
    "\n",
    "    # Create a separate scatter trace for the minimum loss point with a black marker\n",
    "    min_scatter = go.Scatter3d(\n",
    "        x=[min_row[x_col]],\n",
    "        y=[min_row[y_col]],\n",
    "        z=[min_row[z_col]],\n",
    "        mode='markers',\n",
    "        marker=dict(size=8, color='red'),\n",
    "        hovertext=f\"Minimum {z_col}: {min_row[z_col]}<br>{x_col}: {min_row[x_col]}<br>{y_col}: {min_row[y_col]}<br>Learning Rate: {min_row['lr']}\",\n",
    "        hoverinfo=\"text\"\n",
    "        # name='Minimum Loss'\n",
    "    )\n",
    "\n",
    "    # Create the figure and add the surface, scatter plot, and min scatter plot\n",
    "    fig = go.Figure(data=[surface, scatter_data, min_scatter])\n",
    "\n",
    "    # Update axis types to logarithmic if requested\n",
    "    axis_settings = dict(\n",
    "        xaxis=dict(title=x_col, type='log' if log_x else 'linear'),\n",
    "        yaxis=dict(title=y_col, type='log' if log_y else 'linear'),\n",
    "        zaxis=dict(title=z_col, type='log' if log_z else 'linear')\n",
    "    )\n",
    "\n",
    "    # Update the layout for better visualization\n",
    "    fig.update_layout(\n",
    "        width=800,\n",
    "        height=600,\n",
    "        scene=dict(\n",
    "            aspectratio=dict(x=1.25, y=1, z=1),\n",
    "            xaxis=axis_settings['xaxis'],\n",
    "            yaxis=axis_settings['yaxis'],\n",
    "            zaxis=axis_settings['zaxis']\n",
    "        ),\n",
    "        margin=dict(l=0.5, r=0.5, b=50, t=50),\n",
    "        title=f'{dataset_name.upper()}. {reg_type.upper()}. {z_col} as a function of {x_col} and {y_col})' \n",
    "    )\n",
    "\n",
    "    # Show the plot\n",
    "    fig.show()\n",
    "    return fig\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_3d = plot_3d_surface_with_avg(dataset, 'data_size_pct', 'reg_val', 'loss', log_x=False, log_y=log_scale, log_z=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mean_loss(df, x_axis='data_size_pct', group_by='reg_val', log_x=False):\n",
    "    \"\"\"\n",
    "    Plots the mean loss as a function of x_axis for each unique group_by value using Plotly subplots.\n",
    "    Each marker in the scatter plot is accompanied by an error bar representing the spread of the data.\n",
    "\n",
    "    Parameters:\n",
    "    - df: pandas DataFrame containing the data.\n",
    "    - x_axis: column name to use for the x-axis ('data_size_pct' or 'reg_val').\n",
    "    - group_by: column name to group the data by ('reg_val' or 'data_size_pct').\n",
    "    - log_x: boolean indicating whether to use a log scale for the x-axis.\n",
    "\n",
    "    Returns:\n",
    "    - Plotly Figure object.\n",
    "    \"\"\"\n",
    "\n",
    "    # Validate inputs\n",
    "    if x_axis not in df.columns:\n",
    "        raise ValueError(f\"x_axis '{x_axis}' not found in DataFrame columns.\")\n",
    "    if group_by not in df.columns:\n",
    "        raise ValueError(f\"group_by '{group_by}' not found in DataFrame columns.\")\n",
    "    if x_axis == group_by:\n",
    "        raise ValueError(\"x_axis and group_by must be different columns.\")\n",
    "\n",
    "    # Make a copy of the DataFrame to avoid modifying the original data\n",
    "    df_plot = df.copy()\n",
    "\n",
    "    # Option 2: Adjust x_axis to be positive by shifting if log_x is True\n",
    "    shift_value = 0  # Initialize shift value\n",
    "    if log_x:\n",
    "        min_x = df_plot[x_axis].min()\n",
    "        if min_x <= 0:\n",
    "            shift_value = abs(min_x) + 1e-6  # Small constant to ensure positivity\n",
    "            df_plot[x_axis] = df_plot[x_axis] + shift_value\n",
    "            print(f\"Shifted '{x_axis}' by {shift_value} to make all values positive for log scale.\")\n",
    "\n",
    "    # Compute mean and standard deviation of loss grouped by 'group_by' and 'x_axis'\n",
    "    grouped = df_plot.groupby([group_by, x_axis])[['loss', 'lr']].agg({'loss': ['mean', 'std'], 'lr': 'mean'}).reset_index()\n",
    "    grouped.columns = [group_by, x_axis, 'loss_mean', 'loss_std', 'lr_mean']\n",
    "\n",
    "\n",
    "    # Get unique groups\n",
    "    unique_groups = sorted(grouped[group_by].unique())\n",
    "\n",
    "    # Determine number of subplots (n rows x 2 columns)\n",
    "    n = len(unique_groups)\n",
    "    cols = 2\n",
    "    rows = math.ceil(n / cols)\n",
    "\n",
    "    # Create subplot titles\n",
    "    subplot_titles = [f\"{group_by} = {g}\" for g in unique_groups]\n",
    "\n",
    "    # Create subplots\n",
    "    fig = make_subplots(rows=rows, cols=cols, subplot_titles=subplot_titles)\n",
    "\n",
    "    # Determine global x and y ranges\n",
    "    x_min = grouped[x_axis].min()\n",
    "    x_max = grouped[x_axis].max()\n",
    "    y_min = grouped['loss_mean'].min()\n",
    "    y_max = grouped['loss_mean'].max()\n",
    "\n",
    "    # Add padding (5% of the range on each side for x, 15% for y)\n",
    "    x_padding = (x_max - x_min) * 0.05 if x_max != x_min else 1\n",
    "    y_padding = (y_max - y_min) * 0.15 if y_max != y_min else 1\n",
    "\n",
    "    # Calculate final ranges\n",
    "    if log_x:\n",
    "        # For log scales, padding should be multiplicative\n",
    "        x_range = [x_min / 1.1, x_max * 1.1]\n",
    "    else:\n",
    "        x_range = [x_min - x_padding, x_max + x_padding]\n",
    "    y_range = [y_min - y_padding, y_max + y_padding]\n",
    "\n",
    "    for i, group in enumerate(unique_groups):\n",
    "        row = i // cols + 1\n",
    "        col = i % cols + 1\n",
    "        df_group = grouped[grouped[group_by] == group].sort_values(by=x_axis)\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=df_group[x_axis],\n",
    "                y=df_group['loss_mean'],\n",
    "                mode='lines+markers',\n",
    "                name=str(group),\n",
    "                error_y=dict(\n",
    "                    type='data',\n",
    "                    array=df_group['loss_std'],\n",
    "                    visible=True\n",
    "                ),\n",
    "                hovertext=[\n",
    "                    f\"{x_axis}: {x}<br>Mean Loss: {loss}<br>Avg Learning Rate: {lr}\"\n",
    "                    for x, loss, lr in zip(df_group[x_axis], df_group['loss_mean'], df_group['lr_mean'])\n",
    "                ],\n",
    "                hoverinfo=\"text\"\n",
    "            ),\n",
    "            row=row,\n",
    "            col=col\n",
    "        )\n",
    "\n",
    "\n",
    "        # Set x-axis to log if needed, ensuring x_range values are positive for log scale\n",
    "        if log_x:\n",
    "            if x_range[0] > 0 and x_range[1] > 0:\n",
    "                fig.update_xaxes(\n",
    "                    type='log',\n",
    "                    range=[math.log10(x_range[0]), math.log10(x_range[1])],\n",
    "                    row=row,\n",
    "                    col=col\n",
    "                )\n",
    "            else:\n",
    "                raise ValueError(\"Cannot apply log scale to non-positive x_range values after shifting.\")\n",
    "        else:\n",
    "            fig.update_xaxes(range=x_range, row=row, col=col)\n",
    "\n",
    "        # Set y-axis range\n",
    "        fig.update_yaxes(range=y_range, row=row, col=col)\n",
    "\n",
    "        # Set axis titles\n",
    "        fig.update_yaxes(title_text=\"Mean Loss\", row=row, col=col)\n",
    "        # Adjust x-axis title if shifted\n",
    "        if log_x and shift_value != 0:\n",
    "            fig.update_xaxes(title_text=f\"{x_axis} + {shift_value:.2e}\", row=row, col=col)\n",
    "        else:\n",
    "            fig.update_xaxes(title_text=x_axis, row=row, col=col)\n",
    "\n",
    "    # If there are empty subplots, remove their annotations\n",
    "    total_subplots = rows * cols\n",
    "    existing_annotations = len(fig.layout.annotations)\n",
    "    if n < total_subplots:\n",
    "        for i in range(n, total_subplots):\n",
    "            if i < existing_annotations:\n",
    "                fig.layout.annotations[i].text = ''\n",
    "\n",
    "    fig.update_layout(\n",
    "        height=320*rows, \n",
    "        width=1000, \n",
    "        title_text=f\"Mean Loss vs {x_axis} grouped by {group_by}\",\n",
    "        showlegend=False\n",
    "    )\n",
    "    fig.show()\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_reg_val = plot_mean_loss(dataset, x_axis='data_size_pct', group_by='reg_val', log_x=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data_size_pct = plot_mean_loss(dataset, x_axis='reg_val', group_by='data_size_pct', log_x=log_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_plots_to_html(plot_list, file_name):\n",
    "    \"\"\"\n",
    "    Saves multiple Plotly plots into a single HTML file.\n",
    "\n",
    "    Parameters:\n",
    "    - plot_list: A list of variable names (strings) that refer to Plotly plot objects.\n",
    "    - file_name: The name of the HTML file to save the plots.\n",
    "    \"\"\"\n",
    "    # Initialize an empty list to store the HTML content of each plot\n",
    "    html_content = []\n",
    "\n",
    "    # Loop through the list of plot variables, render the plot and append its HTML content\n",
    "    for plot_var in plot_list:\n",
    "        plot = eval(plot_var)  # Evaluate the string to get the actual plot object\n",
    "        html_content.append(pio.to_html(plot, full_html=False))\n",
    "\n",
    "    # Concatenate all plots into a single HTML string\n",
    "    full_html = \"<html><head></head><body>\" + \"\".join(html_content) + \"</body></html>\"\n",
    "\n",
    "    # Save the HTML content to the file\n",
    "    with open(file_name, \"w\", encoding='utf-8') as f:\n",
    "        f.write(full_html)\n",
    "\n",
    "    print(f\"Plots saved to {file_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_list = ['plot_3d', 'plot_reg_val', 'plot_data_size_pct']\n",
    "html_filename = f'{dataset_name.upper()}_{reg_type}_plots.html'\n",
    "save_plots_to_html(plot_list, html_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_lab_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

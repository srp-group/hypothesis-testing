{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract details from a single .txt file\n",
    "def parse_txt_file(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        content = file.read()\n",
    "\n",
    "    # Extract general information\n",
    "    date_time = re.search(r\"Date and Time: (.+)\", content).group(1)\n",
    "    dataset_name = re.search(r\"Dataset Name: (.+)\", content).group(1)\n",
    "    reg_type = re.search(r\"Regularization Type: (.+)\", content).group(1)\n",
    "    total_run_time = re.search(r\"Total Run Time: (.+)\", content).group(1)\n",
    "\n",
    "    # Extract experiment parameters\n",
    "    random_seeds = re.search(r\"Random Seeds: \\[(.+)\\]\", content).group(1)\n",
    "    dataset_sizes = re.search(r\"Dataset Sizes: \\[(.+)\\]\", content).group(1)\n",
    "    reg_values = re.search(r\"Regularization Values: \\[(.+)\\]\", content).group(1)\n",
    "    learning_rates = re.search(r\"Learning Rates: \\[(.+)\\]\", content).group(1)\n",
    "    total_combinations = re.search(r\"Total Combinations: (\\d+)\", content).group(1)\n",
    "\n",
    "    # Extract training details\n",
    "    batch_size = re.search(r\"Batch Size: (\\d+)\", content).group(1)\n",
    "    epochs = re.search(r\"Epochs: (\\d+)\", content).group(1)\n",
    "\n",
    "    # Extract performance\n",
    "    best_hyperparams = re.search(r\"Best Hyperparameters:\\s+Seed: (\\d+)\\s+Data Size Percentage: (\\d+)%\\s+Regularization Value: ([\\d.e-]+)\\s+Learning Rate: ([\\d.e-]+)\", content)\n",
    "    best_seed = best_hyperparams.group(1)\n",
    "    best_data_size_pct = best_hyperparams.group(2)\n",
    "    best_reg_val = best_hyperparams.group(3)\n",
    "    best_lr = best_hyperparams.group(4)\n",
    "\n",
    "    best_results = re.search(r\"Best Results:\\s+Train Loss: ([\\d.e-]+)\\s+Train Accuracy: ([\\d.]+)%\\s+Test Loss: ([\\d.e-]+)\\s+Test Accuracy: ([\\d.]+)%\", content)\n",
    "    train_loss = best_results.group(1)\n",
    "    train_accuracy = best_results.group(2)\n",
    "    test_loss = best_results.group(3)\n",
    "    test_accuracy = best_results.group(4)\n",
    "\n",
    "    # Extract dataset details\n",
    "    total_samples = re.search(r\"Total Samples: (\\d+)\", content).group(1)\n",
    "    train_split = re.search(r\"Training Split: ([\\d.]+)%\", content).group(1)\n",
    "    test_split = re.search(r\"Testing Split: ([\\d.]+)%\", content).group(1)\n",
    "\n",
    "    # Extract notes\n",
    "    notes = re.search(r\"Notes:\\s+([\\s\\S]+?)\\n\\n\", content).group(1).strip()\n",
    "\n",
    "    # Extract model details\n",
    "    model_type = re.search(r\"Model Type: (.+)\", content).group(1)\n",
    "    model_architecture = re.search(r\"Model Architecture:\\s+([\\s\\S]+?)\\n\\s*Optimizer:\", content).group(1).strip()\n",
    "    optimizer = re.search(r\"Optimizer: (.+)\", content).group(1)\n",
    "    loss_function = re.search(r\"Loss Function: (.+)\", content).group(1)\n",
    "\n",
    "    # Return as a dictionary\n",
    "    return {\n",
    "        \"file_name\": os.path.basename(file_path),\n",
    "        \"date_time\": date_time,\n",
    "        \"dataset_name\": dataset_name,\n",
    "        \"reg_type\": reg_type,\n",
    "        \"run_time\": total_run_time,\n",
    "        \"seeds\": random_seeds,\n",
    "        \"data_size\": dataset_sizes,\n",
    "        \"reg_values\": reg_values,\n",
    "        \"learn_rates\": learning_rates,\n",
    "        \"combinations\": total_combinations,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"epochs\": epochs,\n",
    "        \"best_seed\": best_seed,\n",
    "        \"best_data_size\": best_data_size_pct,\n",
    "        \"best_reg_value\": best_reg_val,\n",
    "        \"best_learn_rate\": best_lr,\n",
    "        \"train_loss\": train_loss,\n",
    "        \"train_acc\": train_accuracy,\n",
    "        \"test_loss\": test_loss,\n",
    "        \"test_acc\": test_accuracy,\n",
    "        \"total_samples\": total_samples,\n",
    "        \"train_split\": train_split,\n",
    "        \"test_split\": test_split,\n",
    "        \"notes\": notes,\n",
    "        \"model_type\": model_type,\n",
    "        \"model_arch\": model_architecture,\n",
    "        \"optimizer\": optimizer,\n",
    "        \"loss_function\": loss_function\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\canel\\\\OneDrive\\\\Desktop\\\\SRP\\\\hypothesis-testing3\\\\hypothesis-testing\\\\Variation_vs_Seeds\\\\dna\\\\experiments.csv'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Folder containing .txt files\n",
    "folder_path = r\"C:\\Users\\canel\\OneDrive\\Desktop\\SRP\\hypothesis-testing3\\hypothesis-testing\\Variation_vs_Seeds\\dna\"\n",
    "output_name = 'experiments.csv'\n",
    "\n",
    "output_path = os.path.join(folder_path, output_name)\n",
    "output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of .txt files read: 15\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>date_time</th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>reg_type</th>\n",
       "      <th>run_time</th>\n",
       "      <th>seeds</th>\n",
       "      <th>data_size</th>\n",
       "      <th>reg_values</th>\n",
       "      <th>learn_rates</th>\n",
       "      <th>combinations</th>\n",
       "      <th>...</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>total_samples</th>\n",
       "      <th>train_split</th>\n",
       "      <th>test_split</th>\n",
       "      <th>notes</th>\n",
       "      <th>model_type</th>\n",
       "      <th>model_arch</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>loss_function</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dna_l2_summary_20241129_192553.txt</td>\n",
       "      <td>2024-11-29 19:25:53</td>\n",
       "      <td>dna</td>\n",
       "      <td>l2</td>\n",
       "      <td>04:29:39</td>\n",
       "      <td>1, 2, 3</td>\n",
       "      <td>1, 5, 10, 25, 50, 75, 100</td>\n",
       "      <td>0.0, 1e-05, 0.001, 0.1</td>\n",
       "      <td>1e-05, 0.001, 0.1</td>\n",
       "      <td>252</td>\n",
       "      <td>...</td>\n",
       "      <td>1.2747</td>\n",
       "      <td>93.18</td>\n",
       "      <td>3186</td>\n",
       "      <td>60</td>\n",
       "      <td>40</td>\n",
       "      <td>Write any comments about the experiment here.</td>\n",
       "      <td>MLP</td>\n",
       "      <td>- Linear(180 -&gt; 2048)\\n    - ReLU\\n    - Linea...</td>\n",
       "      <td>Adam</td>\n",
       "      <td>CrossEntropyLoss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dna_l2_summary_20241130_045257.txt</td>\n",
       "      <td>2024-11-30 04:52:57</td>\n",
       "      <td>dna</td>\n",
       "      <td>l2</td>\n",
       "      <td>00:09:49</td>\n",
       "      <td>1, 2, 3</td>\n",
       "      <td>100, 75, 50, 25, 10, 5, 1</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>0.001</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>0.7272</td>\n",
       "      <td>93.33</td>\n",
       "      <td>3186</td>\n",
       "      <td>60</td>\n",
       "      <td>40</td>\n",
       "      <td>Write any comments about the experiment here.</td>\n",
       "      <td>MLP</td>\n",
       "      <td>- Linear(180 -&gt; 2048)\\n    - ReLU\\n    - Linea...</td>\n",
       "      <td>Adam</td>\n",
       "      <td>CrossEntropyLoss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dna_l2_summary_20241130_050400.txt</td>\n",
       "      <td>2024-11-30 05:04:00</td>\n",
       "      <td>dna</td>\n",
       "      <td>l2</td>\n",
       "      <td>00:06:49</td>\n",
       "      <td>4, 5</td>\n",
       "      <td>100, 75, 50, 25, 10, 5, 1</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>0.001</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>0.7814</td>\n",
       "      <td>92.63</td>\n",
       "      <td>3186</td>\n",
       "      <td>60</td>\n",
       "      <td>40</td>\n",
       "      <td>Write any comments about the experiment here.</td>\n",
       "      <td>MLP</td>\n",
       "      <td>- Linear(180 -&gt; 2048)\\n    - ReLU\\n    - Linea...</td>\n",
       "      <td>Adam</td>\n",
       "      <td>CrossEntropyLoss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dna_l2_summary_20241130_051151.txt</td>\n",
       "      <td>2024-11-30 05:11:51</td>\n",
       "      <td>dna</td>\n",
       "      <td>l2</td>\n",
       "      <td>00:16:22</td>\n",
       "      <td>6, 7, 8, 9, 10</td>\n",
       "      <td>100, 75, 50, 25, 10, 5, 1</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>0.001</td>\n",
       "      <td>35</td>\n",
       "      <td>...</td>\n",
       "      <td>1.3668</td>\n",
       "      <td>92.63</td>\n",
       "      <td>3186</td>\n",
       "      <td>60</td>\n",
       "      <td>40</td>\n",
       "      <td>Write any comments about the experiment here.</td>\n",
       "      <td>MLP</td>\n",
       "      <td>- Linear(180 -&gt; 2048)\\n    - ReLU\\n    - Linea...</td>\n",
       "      <td>Adam</td>\n",
       "      <td>CrossEntropyLoss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dna_l2_summary_20241130_053407.txt</td>\n",
       "      <td>2024-11-30 05:34:07</td>\n",
       "      <td>dna</td>\n",
       "      <td>l2</td>\n",
       "      <td>00:32:13</td>\n",
       "      <td>11, 12, 13, 14, 15, 16, 17, 18, 19, 20</td>\n",
       "      <td>100, 75, 50, 25, 10, 5, 1</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>0.001</td>\n",
       "      <td>70</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4301</td>\n",
       "      <td>93.73</td>\n",
       "      <td>3186</td>\n",
       "      <td>60</td>\n",
       "      <td>40</td>\n",
       "      <td>Write any comments about the experiment here.</td>\n",
       "      <td>MLP</td>\n",
       "      <td>- Linear(180 -&gt; 2048)\\n    - ReLU\\n    - Linea...</td>\n",
       "      <td>Adam</td>\n",
       "      <td>CrossEntropyLoss</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            file_name            date_time dataset_name  \\\n",
       "0  dna_l2_summary_20241129_192553.txt  2024-11-29 19:25:53          dna   \n",
       "1  dna_l2_summary_20241130_045257.txt  2024-11-30 04:52:57          dna   \n",
       "2  dna_l2_summary_20241130_050400.txt  2024-11-30 05:04:00          dna   \n",
       "3  dna_l2_summary_20241130_051151.txt  2024-11-30 05:11:51          dna   \n",
       "4  dna_l2_summary_20241130_053407.txt  2024-11-30 05:34:07          dna   \n",
       "\n",
       "  reg_type  run_time                                   seeds  \\\n",
       "0       l2  04:29:39                                 1, 2, 3   \n",
       "1       l2  00:09:49                                 1, 2, 3   \n",
       "2       l2  00:06:49                                    4, 5   \n",
       "3       l2  00:16:22                          6, 7, 8, 9, 10   \n",
       "4       l2  00:32:13  11, 12, 13, 14, 15, 16, 17, 18, 19, 20   \n",
       "\n",
       "                   data_size              reg_values        learn_rates  \\\n",
       "0  1, 5, 10, 25, 50, 75, 100  0.0, 1e-05, 0.001, 0.1  1e-05, 0.001, 0.1   \n",
       "1  100, 75, 50, 25, 10, 5, 1                   1e-05              0.001   \n",
       "2  100, 75, 50, 25, 10, 5, 1                   1e-05              0.001   \n",
       "3  100, 75, 50, 25, 10, 5, 1                   1e-05              0.001   \n",
       "4  100, 75, 50, 25, 10, 5, 1                   1e-05              0.001   \n",
       "\n",
       "  combinations  ... test_loss test_acc total_samples train_split test_split  \\\n",
       "0          252  ...    1.2747    93.18          3186          60         40   \n",
       "1           21  ...    0.7272    93.33          3186          60         40   \n",
       "2           14  ...    0.7814    92.63          3186          60         40   \n",
       "3           35  ...    1.3668    92.63          3186          60         40   \n",
       "4           70  ...    0.4301    93.73          3186          60         40   \n",
       "\n",
       "                                           notes model_type  \\\n",
       "0  Write any comments about the experiment here.        MLP   \n",
       "1  Write any comments about the experiment here.        MLP   \n",
       "2  Write any comments about the experiment here.        MLP   \n",
       "3  Write any comments about the experiment here.        MLP   \n",
       "4  Write any comments about the experiment here.        MLP   \n",
       "\n",
       "                                          model_arch optimizer  \\\n",
       "0  - Linear(180 -> 2048)\\n    - ReLU\\n    - Linea...      Adam   \n",
       "1  - Linear(180 -> 2048)\\n    - ReLU\\n    - Linea...      Adam   \n",
       "2  - Linear(180 -> 2048)\\n    - ReLU\\n    - Linea...      Adam   \n",
       "3  - Linear(180 -> 2048)\\n    - ReLU\\n    - Linea...      Adam   \n",
       "4  - Linear(180 -> 2048)\\n    - ReLU\\n    - Linea...      Adam   \n",
       "\n",
       "      loss_function  \n",
       "0  CrossEntropyLoss  \n",
       "1  CrossEntropyLoss  \n",
       "2  CrossEntropyLoss  \n",
       "3  CrossEntropyLoss  \n",
       "4  CrossEntropyLoss  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Collect data from all .txt files\n",
    "data = []\n",
    "txt_file_count = 0  # Counter for files processed\n",
    "for file_name in os.listdir(folder_path):\n",
    "    if file_name.endswith('.txt'):\n",
    "        txt_file_count += 1\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        data.append(parse_txt_file(file_path))\n",
    "\n",
    "# Print the number of files read\n",
    "print(f\"Number of .txt files read: {txt_file_count}\")\n",
    "\n",
    "# Create a dataframe\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(output_path) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

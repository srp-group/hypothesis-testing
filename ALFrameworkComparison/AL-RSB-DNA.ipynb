{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "h:\\Uni\\WiSe 2024\\ML LAB\\ml_lab_venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Subset, ConcatDataset, Dataset\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from torch import nn, optim\n",
    "from torcheval import metrics\n",
    "from sklearn.preprocessing import FunctionTransformer, OneHotEncoder\n",
    "import requests\n",
    "import os\n",
    "from sklearn.datasets import load_svmlight_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the data\n",
    "n_features = 180\n",
    "budget = 200\n",
    "n_classes = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dna(Dataset):\n",
    "    dataset_name = \"dna\"\n",
    "    feature_encoder =  FunctionTransformer(lambda x: x)\n",
    "    target_encoder = OneHotEncoder(sparse_output=False)\n",
    "    visualize = False\n",
    "    configs = None\n",
    "    random_seed = 42\n",
    "    urls_dict = {\"train\":\"https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/multiclass/dna.scale.tr\",\n",
    "                \"val\":\"https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/multiclass/dna.scale.val\",\n",
    "                \"test\":\"https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/multiclass/dna.scale.t\"}\n",
    "    def __init__(self, split_name):\n",
    "        super().__init__()\n",
    "        self.location = \"datasets/data/\" + self.dataset_name\n",
    "        if not os.path.exists(self.location):\n",
    "            os.makedirs(self.location)\n",
    "        self.split_name = split_name\n",
    "\n",
    "        if not self.file_exists():\n",
    "            data = self.obtain()\n",
    "            data = self.split(data)\n",
    "            data = self.preprocess(data)\n",
    "            self.save_npz(data)            \n",
    "\n",
    "        self.load_clean()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.x.shape[0]\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]\n",
    "    def file_exists(self):\n",
    "        splits = [\"train.npz\", \"test.npz\"]\n",
    "        existed_files = os.listdir(self.location)\n",
    "        return all([elem in existed_files for elem in splits])\n",
    "    \n",
    "    def load_clean(self):\n",
    "        with np.load(f\"{self.location}/{self.split_name}.npz\", allow_pickle=True) as file:\n",
    "            self.x = file[\"x\"].astype(np.float32)\n",
    "            self.y = file[\"y\"].astype(np.float32)\n",
    "    \n",
    "    def save_npz(self, data_dict):\n",
    "        for split_name, data in data_dict.items():\n",
    "            with open(f\"{self.location}/{split_name}.npz\", \"wb\") as f:\n",
    "                np.savez(f, x=data[\"x\"], y=data[\"y\"])   \n",
    "\n",
    "    def preprocess(self, data):\n",
    "        for data_shard in data.values():\n",
    "            x, y = data_shard[\"x\"], data_shard[\"y\"]\n",
    "            self.feature_encoder.fit(x)\n",
    "            self.target_encoder.fit(y)\n",
    "            \n",
    "        for shard_name, data_shard in data.items():\n",
    "            x, y = data_shard[\"x\"], data_shard[\"y\"]\n",
    "            data[shard_name][\"x\"] = self.feature_encoder.transform(x)\n",
    "            data[shard_name][\"y\"] = self.target_encoder.transform(y)\n",
    "        return data\n",
    "    def split(self, data):\n",
    "        data[\"train\"][\"x\"] = np.concatenate((data[\"train\"][\"x\"], data[\"val\"][\"x\"].copy()))\n",
    "        data[\"train\"][\"y\"] = np.concatenate((data[\"train\"][\"y\"], data[\"val\"][\"y\"].copy()))\n",
    "\n",
    "        data.pop(\"val\", None)\n",
    "        return data\n",
    "    def obtain(self):\n",
    "        data = {}\n",
    "        for split_name, url in self.urls_dict.items():\n",
    "            file_path = f\"{self.location}_{split_name}_raw\"\n",
    "            with open(file_path, 'w') as f:\n",
    "                r = requests.get(url)\n",
    "                f.writelines(r.content.decode(\"utf-8\"))\n",
    "            x, y  = load_svmlight_file(file_path, n_features=n_features)\n",
    "            data[split_name] = {\"x\": np.asarray(x.todense(), dtype=np.float32), \"y\": y.reshape(-1, 1)}\n",
    "            os.remove(file_path)\n",
    "        \n",
    "        return data\n",
    "    @classmethod\n",
    "    def get_data_dict(cls):\n",
    "        return {\"train\": cls(split_name=\"train\"), \n",
    "                \"test\": cls(split_name=\"test\")}\n",
    "    \n",
    "    @staticmethod\n",
    "    def conv_split(array_size, shares=[0.6, 0.2], seed=42):\n",
    "        indices = np.arange(array_size)\n",
    "        idx_to_split = (np.cumsum(shares)*array_size).astype(int)\n",
    "        np.random.seed(seed)\n",
    "        permutated_idx = np.random.choice(indices, array_size, replace=False)\n",
    "        return np.split(permutated_idx, idx_to_split)\n",
    "\n",
    "    @staticmethod\n",
    "    def step_split(array_size, val_chunk):\n",
    "        indices = np.arange(array_size)\n",
    "        train_idx = np.random.choice(indices[:-val_chunk], indices[:-val_chunk].shape[0], replace=False)\n",
    "        val_idx = indices[-val_chunk:]\n",
    "        return train_idx, val_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the pool\n",
    "class Pool:\n",
    "    def __init__(self, data, random_seed = 42, val_share=0.25, n_initially_labeled=1000, batch_size=32):\n",
    "        self.random_seed = random_seed\n",
    "        self.set_seed(self.random_seed)\n",
    "        self.data = data\n",
    "        self.batch_size = batch_size\n",
    "        self.idx_abs = np.arange(len(self.data[\"train\"].x)) # Absolute index attribute\n",
    "        self.val_share = val_share\n",
    "        self.n_initially_labeled = n_initially_labeled\n",
    "        self.set_seed(self.random_seed)\n",
    "        self.idx_unviolated_lb = np.random.choice(self.idx_abs, size=self.n_initially_labeled, replace=False)\n",
    "        self.idx_new_lb = np.array([], dtype=int)\n",
    "        self.set_seed(self.random_seed)\n",
    "        self.test_loader = DataLoader(data[\"test\"], batch_size=self.batch_size, shuffle=False)\n",
    "        self.set_seed(self.random_seed)\n",
    "        self.splitter = ShuffleSplit(n_splits=6, \n",
    "                        test_size=self.val_share,\n",
    "                        random_state=self.random_seed)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[\"train\"][idx]\n",
    "    \n",
    "    @property\n",
    "    def drop_last(self):\n",
    "        # drop last if the number of labeled instances is bigger than the batch_size\n",
    "        return int(self.get_len(\"unviolated\")*(1-self.val_share)) + self.get_len(\"new_labeled\") > self.batch_size \n",
    "\n",
    "    @property\n",
    "    def idx_all_labeled(self):\n",
    "        return np.append(self.idx_unviolated_lb, self.idx_new_lb)\n",
    "    \n",
    "    @property\n",
    "    def new_lb_dataset(self):\n",
    "        return Subset(self.data['train'], self.idx_new_lb)\n",
    "    \n",
    "    @property\n",
    "    def unviolated_lb_dataset(self):\n",
    "        return Subset(self.data['train'], self.idx_unviolated_lb)\n",
    "    \n",
    "    @property\n",
    "    def all_lb_dataset(self):\n",
    "        return Subset(self.data['train'], self.idx_all_labeled)\n",
    "    \n",
    "    @property\n",
    "    def idx_ulb(self):\n",
    "        return np.delete(self.idx_abs, self.idx_all_labeled) \n",
    "    \n",
    "    def one_split(self):\n",
    "        self.set_seed(seed=self.random_seed)\n",
    "        return next(self.splitter.split(self.unviolated_lb_dataset))\n",
    "    \n",
    "    def CV_splits(self):\n",
    "        self.set_seed(seed=self.const_seed)\n",
    "        return self.splitter.split(self.unviolated_lb_dataset)\n",
    "    def get_train_val_loaders(self, unviolated_train_idx, unviolated_val_idx):\n",
    "        unviolated_train_ds = Subset(self.unviolated_lb_dataset, unviolated_train_idx)\n",
    "        unviolated_val_ds = Subset(self.unviolated_lb_dataset, unviolated_val_idx)\n",
    "\n",
    "        self.set_seed(seed=self.random_seed)\n",
    "        train_loader = DataLoader(ConcatDataset((unviolated_train_ds, self.new_lb_dataset)),\n",
    "                                batch_size=self.batch_size, \n",
    "                                drop_last=self.drop_last,\n",
    "                                shuffle=True)\n",
    "        \n",
    "        val_loader = DataLoader(unviolated_val_ds, batch_size=self.batch_size, shuffle=False)\n",
    "        return train_loader, val_loader\n",
    "\n",
    "    def get_len(self, pool=\"total\"):\n",
    "        return len(self.get(pool)[0])\n",
    "    \n",
    "    def add_new_inst(self, idx):\n",
    "        assert len(self.idx_ulb)\n",
    "        self.idx_new_lb = np.append(self.idx_new_lb, idx)\n",
    "\n",
    "    def get(self, pool):\n",
    "        if pool == \"all_labeled\":\n",
    "            return self[self.idx_all_labeled]\n",
    "        elif pool == \"unviolated\":\n",
    "            return self[self.idx_unviolated_lb] \n",
    "        elif pool == \"new_labeled\":\n",
    "            return self[self.idx_new_lb] \n",
    "        elif pool == \"unlabeled\":\n",
    "            return self[self.idx_ulb] \n",
    "        elif pool == \"total\":\n",
    "            return self[:]\n",
    "        elif pool == \"test\":\n",
    "            return self.data[\"test\"][:]\n",
    "        else:\n",
    "            raise NameError(\"There is no such name in the pool\")\n",
    "        \n",
    "    def set_seed(self, seed=None):\n",
    "        seed = self.random_seed\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        torch.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        np.random.seed(seed)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# The Acquisition function\n",
    "class Random():\n",
    "    def __init__(self, \n",
    "                clf,\n",
    "                pool,\n",
    "                random_seed = 42,\n",
    "                budget = budget):\n",
    "        self.clf = clf       \n",
    "        self.pool = pool\n",
    "        self.random_seed = random_seed\n",
    "        self.budget = budget\n",
    "    def get_scores(self, values=None):\n",
    "        if values is None:\n",
    "            values = self.pool.get_len(\"unlabeled\")\n",
    "        else:\n",
    "            values = values[:, 0].ravel().shape[0]\n",
    "        return np.random.random(values)\n",
    "    def query(self):\n",
    "        all_scores = self.get_scores()\n",
    "        max_scores = np.argwhere(np.isclose(all_scores, all_scores.max())).ravel()            \n",
    "        self.pool.set_seed(self.random_seed)\n",
    "        idx = np.random.choice(max_scores, 1)[0]\n",
    "        return self.pool.idx_ulb[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential()\n",
    "        self.layers.add_module(f\"dense_0\", nn.Linear(n_features, n_features//5))\n",
    "        self.layers.add_module(f\"activation_0\", nn.ReLU())\n",
    "        self.layers.add_module(f\"dense_1\", nn.Linear(n_features//5, n_features//10))\n",
    "        self.layers.add_module(f\"activation_1\", nn.ReLU())\n",
    "        self.layers.add_module(f\"dense_2\", nn.Linear(n_features//10, n_classes))\n",
    "        self.layers.add_module(f\"activation_2\", nn.Softmax())\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.optimizer = torch.optim.SGD(self.parameters(), lr=0.01, weight_decay=0.01)\n",
    "        self.metric = metrics.MulticlassAccuracy(num_classes=n_classes)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "    \n",
    "    def calculate_accuracy(self, y_pred, y_true):\n",
    "        self.metric.update(y_pred, y_true)\n",
    "\n",
    "        # compute the metric\n",
    "        accuracy = self.metric.compute()\n",
    "\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OnlineAvg:\n",
    "    def __init__(self, val=0):\n",
    "        self.n = 1\n",
    "        self.val = float(val)\n",
    "        \n",
    "    def __add__(self, other):\n",
    "        self.val = self.val + (other-self.val)/self.n\n",
    "        self.n += 1\n",
    "        return self\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return str(self.val)\n",
    "    \n",
    "    def __float__(self):\n",
    "        return self.val\n",
    "    \n",
    "    def __int__(self):\n",
    "        return self.n\n",
    "    \n",
    "    def __sub__(self, other):\n",
    "        return float(self.val - float(other))\n",
    "    \n",
    "    def __le__(self, other):\n",
    "        return self.val <= float(other)\n",
    "    \n",
    "    def __lt__(self, other):\n",
    "        return self.val < float(other)\n",
    "\n",
    "    def __truediv__(self, other):\n",
    "        return self.val / float(other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Learnable():\n",
    "    def __init__(self, \n",
    "                pool,\n",
    "                random_seed = 42,\n",
    "                n_warmup_epochs=100,\n",
    "                patience=20,\n",
    "                epochs=200):\n",
    "        \n",
    "        self.random_seed = random_seed\n",
    "        self.n_warmup_epochs = n_warmup_epochs\n",
    "        self.epochs = epochs\n",
    "        self.patience = patience\n",
    "        self.pool = pool\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model = NN()   \n",
    "        \n",
    "    def __call__(self, x, mc_dropout=False):\n",
    "        if mc_dropout:\n",
    "            self.model.train()\n",
    "        else:\n",
    "            self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            return self.model(x.to(self.device))\n",
    "    \n",
    "    def train_model(self):\n",
    "        unviolated_train_idx, unviolated_val_idx = self.pool.one_split()\n",
    "        train_loader, val_loader = self.pool.get_train_val_loaders(unviolated_train_idx, unviolated_val_idx)\n",
    "        train_perf, val_perf = self.fit(train_loader=train_loader, val_loader=val_loader)\n",
    "        test_perf, _ = self.eval(loader=self.pool.test_loader)\n",
    "        return train_perf, val_perf, test_perf\n",
    "\n",
    "    def eval(self, loader):\n",
    "        self.model.eval()\n",
    "        total_loss = OnlineAvg()\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in loader:\n",
    "                targets = targets.to(self.device)\n",
    "                inputs = inputs.to(self.device)\n",
    "                predictions = self(inputs.float())\n",
    "                batch_loss = self.model.criterion(predictions, targets)\n",
    "                total_loss += batch_loss.item()\n",
    "                acc = self.model.calculate_accuracy(predictions, targets)  \n",
    "        return total_loss, acc\n",
    "    \n",
    "    def fit(self, train_loader, val_loader):\n",
    "        self.model.train()      \n",
    "        train_loss = OnlineAvg()  \n",
    "        for epoch_num in range(self.epochs):\n",
    "            for inputs, targets in train_loader:\n",
    "                targets = targets.to(self.device)\n",
    "                inputs = inputs.to(self.device)\n",
    "                predictions = self.model(inputs.float())\n",
    "                batch_loss = self.model.criterion(predictions, targets.float())\n",
    "                train_loss += batch_loss.item()\n",
    "                self.model.zero_grad()\n",
    "                batch_loss.backward()\n",
    "                self.model.optimizer.step()\n",
    "\n",
    "            train_loss, train_metrics = self.eval(loader=train_loader)\n",
    "            val_loss, val_metrics = self.eval(val_loader)\n",
    "        return (train_loss, train_metrics),  (val_loss, val_metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActiveLearning():\n",
    "    def __init__(self):\n",
    "        self.budget = budget\n",
    "        self.random_seed = 42\n",
    "        self.pool = Pool(data=Dna.get_data_dict())\n",
    "        self.clf = Learnable(pool=self.pool)\n",
    "        self.acq = Random(clf=self.clf, pool=self.pool)\n",
    "    \n",
    "    def show_intermediate_results(self, abs_idx, train_perf, val_perf, test_perf):\n",
    "        print(f'{abs_idx} {self.pool.get_len(\"all_labeled\")} {self.pool.get_len(\"unlabeled\")}\\n{train_perf}\\n{val_perf}\\n{test_perf}')\n",
    "    \n",
    "    def train_first_hypers(self):\n",
    "        train_perf, val_perf, test_perf = self.clf.train_model()\n",
    "        print(f\"Initial {train_perf}, {val_perf}, {test_perf}\")\n",
    "        return train_perf, val_perf, test_perf\n",
    "    \n",
    "    def run(self):\n",
    "        abs_idx = None\n",
    "        train_perf, val_perf, test_perf = self.train_first_hypers()\n",
    "        for iteration in range(0, self.budget):\n",
    "            abs_idx = self.acq.query()\n",
    "            self.pool.add_new_inst(abs_idx)\n",
    "            train_perf, val_perf, test_perf = self.clf.train_model()\n",
    "        print(f\"final {train_perf}, {val_perf}, {test_perf}, {abs_idx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "h:\\Uni\\WiSe 2024\\ML LAB\\ml_lab_venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "target should be a one-dimensional tensor, got shape torch.Size([32, 3]).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mActiveLearning\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[10], line 19\u001b[0m, in \u001b[0;36mActiveLearning.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m     18\u001b[0m     abs_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m     train_perf, val_perf, test_perf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_first_hypers\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m iteration \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbudget):\n\u001b[0;32m     21\u001b[0m         abs_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39macq\u001b[38;5;241m.\u001b[39mquery()\n",
      "Cell \u001b[1;32mIn[10], line 13\u001b[0m, in \u001b[0;36mActiveLearning.train_first_hypers\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_first_hypers\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m---> 13\u001b[0m     train_perf, val_perf, test_perf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInitial \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_perf\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_perf\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_perf\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m train_perf, val_perf, test_perf\n",
      "Cell \u001b[1;32mIn[15], line 28\u001b[0m, in \u001b[0;36mLearnable.train_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     26\u001b[0m unviolated_train_idx, unviolated_val_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool\u001b[38;5;241m.\u001b[39mone_split()\n\u001b[0;32m     27\u001b[0m train_loader, val_loader \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool\u001b[38;5;241m.\u001b[39mget_train_val_loaders(unviolated_train_idx, unviolated_val_idx)\n\u001b[1;32m---> 28\u001b[0m train_perf, val_perf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m test_perf, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meval(loader\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool\u001b[38;5;241m.\u001b[39mtest_loader)\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m train_perf, val_perf, test_perf\n",
      "Cell \u001b[1;32mIn[15], line 59\u001b[0m, in \u001b[0;36mLearnable.fit\u001b[1;34m(self, train_loader, val_loader)\u001b[0m\n\u001b[0;32m     56\u001b[0m         batch_loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     57\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m---> 59\u001b[0m     train_loss, train_metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     60\u001b[0m     val_loss, val_metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meval(val_loader)\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (train_loss, train_metrics),  (val_loss, val_metrics)\n",
      "Cell \u001b[1;32mIn[15], line 42\u001b[0m, in \u001b[0;36mLearnable.eval\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m     40\u001b[0m         batch_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mcriterion(predictions, targets)\n\u001b[0;32m     41\u001b[0m         total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m batch_loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m---> 42\u001b[0m         acc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalculate_accuracy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m)\u001b[49m  \n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m total_loss, acc\n",
      "Cell \u001b[1;32mIn[24], line 20\u001b[0m, in \u001b[0;36mNN.calculate_accuracy\u001b[1;34m(self, y_pred, y_true)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalculate_accuracy\u001b[39m(\u001b[38;5;28mself\u001b[39m, y_pred, y_true):\n\u001b[1;32m---> 20\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;66;03m# compute the metric\u001b[39;00m\n\u001b[0;32m     23\u001b[0m     accuracy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetric\u001b[38;5;241m.\u001b[39mcompute()\n",
      "File \u001b[1;32mh:\\Uni\\WiSe 2024\\ML LAB\\ml_lab_venv\\Lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mh:\\Uni\\WiSe 2024\\ML LAB\\ml_lab_venv\\Lib\\site-packages\\torcheval\\metrics\\classification\\accuracy.py:127\u001b[0m, in \u001b[0;36mMulticlassAccuracy.update\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    125\u001b[0m target \u001b[38;5;241m=\u001b[39m target\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m--> 127\u001b[0m num_correct, num_total \u001b[38;5;241m=\u001b[39m \u001b[43m_multiclass_accuracy_update\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_classes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mk\u001b[49m\n\u001b[0;32m    129\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_correct \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m num_correct\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m num_total\n",
      "File \u001b[1;32mh:\\Uni\\WiSe 2024\\ML LAB\\ml_lab_venv\\Lib\\site-packages\\torcheval\\metrics\\functional\\classification\\accuracy.py:258\u001b[0m, in \u001b[0;36m_multiclass_accuracy_update\u001b[1;34m(input, target, average, num_classes, k)\u001b[0m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_multiclass_accuracy_update\u001b[39m(\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;28minput\u001b[39m: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m    252\u001b[0m     target: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    255\u001b[0m     k: \u001b[38;5;28mint\u001b[39m,\n\u001b[0;32m    256\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor, torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m--> 258\u001b[0m     \u001b[43m_accuracy_update_input_check\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    261\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[1;32mh:\\Uni\\WiSe 2024\\ML LAB\\ml_lab_venv\\Lib\\site-packages\\torcheval\\metrics\\functional\\classification\\accuracy.py:330\u001b[0m, in \u001b[0;36m_accuracy_update_input_check\u001b[1;34m(input, target, num_classes, k)\u001b[0m\n\u001b[0;32m    324\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    325\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe `input` and `target` should have the same first dimension, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    326\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgot shapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    327\u001b[0m     )\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m target\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    331\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget should be a one-dimensional tensor, got shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    332\u001b[0m     )\n\u001b[0;32m    334\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m    335\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    336\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput should have shape (num_sample, num_classes) for k > 1, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    337\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgot shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    338\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: target should be a one-dimensional tensor, got shape torch.Size([32, 3])."
     ]
    }
   ],
   "source": [
    "ActiveLearning().run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_lab_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
